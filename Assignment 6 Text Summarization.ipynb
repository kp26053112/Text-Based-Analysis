{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3369f264-4cd5-49cc-b44a-40a8d32af622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8453be1-c75c-4138-9370-4bced5da99a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate change refers to long-term changes in the Earth's climate, including changes in temperature, precipitation, and wind patterns\n",
      "Scientists have observed that human activities, such as burning fossil fuels and deforestation, are contributing to the rapid pace of climate change\n",
      "The consequences of climate change include rising sea levels, more frequent and severe weather events, and disruptions to ecosystems and wildlife\n",
      "Addressing climate change requires global cooperation and sustainable practices to reduce greenhouse gas emissions and mitigate its impacts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"1.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c039ede-62fc-45c0-91e1-09d56d9a818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['Climate', 'change', 'refers', 'to', 'long-term', 'changes', 'in', 'the', \"Earth's\", 'climate,', 'including', 'changes', 'in', 'temperature,', 'precipitation,', 'and', 'wind', 'patterns'], ['Scientists', 'have', 'observed', 'that', 'human', 'activities,', 'such', 'as', 'burning', 'fossil', 'fuels', 'and', 'deforestation,', 'are', 'contributing', 'to', 'the', 'rapid', 'pace', 'of', 'climate', 'change'], ['The', 'consequences', 'of', 'climate', 'change', 'include', 'rising', 'sea', 'levels,', 'more', 'frequent', 'and', 'severe', 'weather', 'events,', 'and', 'disruptions', 'to', 'ecosystems', 'and', 'wildlife'], ['Addressing', 'climate', 'change', 'requires', 'global', 'cooperation', 'and', 'sustainable', 'practices', 'to', 'reduce', 'greenhouse', 'gas', 'emissions', 'and', 'mitigate', 'its', 'impacts.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f6474b-0c56-428d-a410-de9be97ac61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbbc657b-8a34-437a-bacc-60134f0fa0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.22727273 0.28721348 0.23836565]\n",
      " [0.22727273 0.         0.32824398 0.23836565]\n",
      " [0.28721348 0.32824398 0.         0.38729833]\n",
      " [0.23836565 0.23836565 0.38729833 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89844db-a160-41a7-b05a-1ebf4cd2883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.2241068672792711, 1: 0.23457630024272336, 2: 0.2888184366837051, 3: 0.2524983957943003}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bb0a86c-adbd-477f-8fac-7382b4480e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.2888184366837051, ['The', 'consequences', 'of', 'climate', 'change', 'include', 'rising', 'sea', 'levels,', 'more', 'frequent', 'and', 'severe', 'weather', 'events,', 'and', 'disruptions', 'to', 'ecosystems', 'and', 'wildlife']), (0.2524983957943003, ['Addressing', 'climate', 'change', 'requires', 'global', 'cooperation', 'and', 'sustainable', 'practices', 'to', 'reduce', 'greenhouse', 'gas', 'emissions', 'and', 'mitigate', 'its', 'impacts.\\n']), (0.23457630024272336, ['Scientists', 'have', 'observed', 'that', 'human', 'activities,', 'such', 'as', 'burning', 'fossil', 'fuels', 'and', 'deforestation,', 'are', 'contributing', 'to', 'the', 'rapid', 'pace', 'of', 'climate', 'change']), (0.2241068672792711, ['Climate', 'change', 'refers', 'to', 'long-term', 'changes', 'in', 'the', \"Earth's\", 'climate,', 'including', 'changes', 'in', 'temperature,', 'precipitation,', 'and', 'wind', 'patterns'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c22790a-1929-4f13-80b0-f951582cf748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  1\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b514f239-7be8-42ee-9638-d670d0365008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " The consequences of climate change include rising sea levels, more frequent and severe weather events, and disruptions to ecosystems and wildlife\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38cfe26e-a039-4315-b92e-5934a1f07aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La historia del arte abarca una amplia gama de estilos, períodos y movimientos artísticos a lo largo de los siglos\n",
      "Desde las pinturas rupestres prehistóricas hasta las obras maestras renacentistas y las expresiones contemporáneas, el arte ha reflejado la cultura, las creencias y las ideas de diversas sociedades\n",
      "Los artistas han utilizado una variedad de técnicas y materiales para expresar su creatividad y transmitir mensajes emocionales, políticos y sociales a través de sus obras.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"2.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7bd010-9e9b-40e3-b082-3bdfec5b9994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['La', 'historia', 'del', 'arte', 'abarca', 'una', 'amplia', 'gama', 'de', 'estilos,', 'períodos', 'y', 'movimientos', 'artísticos', 'a', 'lo', 'largo', 'de', 'los', 'siglos'], ['Desde', 'las', 'pinturas', 'rupestres', 'prehistóricas', 'hasta', 'las', 'obras', 'maestras', 'renacentistas', 'y', 'las', 'expresiones', 'contemporáneas,', 'el', 'arte', 'ha', 'reflejado', 'la', 'cultura,', 'las', 'creencias', 'y', 'las', 'ideas', 'de', 'diversas', 'sociedades'], ['Los', 'artistas', 'han', 'utilizado', 'una', 'variedad', 'de', 'técnicas', 'y', 'materiales', 'para', 'expresar', 'su', 'creatividad', 'y', 'transmitir', 'mensajes', 'emocionales,', 'políticos', 'y', 'sociales', 'a', 'través', 'de', 'sus', 'obras.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32aeb6ff-3abf-41cc-829f-08d4d2296519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85459348-9eb3-4d86-84b9-0807a8edc8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.18090681 0.36563621]\n",
      " [0.18090681 0.         0.1940285 ]\n",
      " [0.36563621 0.1940285  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9cfe0d-4fbf-446f-9ce5-f51ca6a80f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.36468906977342636, 1: 0.26247470720213906, 2: 0.37283622302443414}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaf3e06c-bf98-49ef-a279-0a4474ff76ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.37283622302443414, ['Los', 'artistas', 'han', 'utilizado', 'una', 'variedad', 'de', 'técnicas', 'y', 'materiales', 'para', 'expresar', 'su', 'creatividad', 'y', 'transmitir', 'mensajes', 'emocionales,', 'políticos', 'y', 'sociales', 'a', 'través', 'de', 'sus', 'obras.\\n']), (0.36468906977342636, ['La', 'historia', 'del', 'arte', 'abarca', 'una', 'amplia', 'gama', 'de', 'estilos,', 'períodos', 'y', 'movimientos', 'artísticos', 'a', 'lo', 'largo', 'de', 'los', 'siglos']), (0.26247470720213906, ['Desde', 'las', 'pinturas', 'rupestres', 'prehistóricas', 'hasta', 'las', 'obras', 'maestras', 'renacentistas', 'y', 'las', 'expresiones', 'contemporáneas,', 'el', 'arte', 'ha', 'reflejado', 'la', 'cultura,', 'las', 'creencias', 'y', 'las', 'ideas', 'de', 'diversas', 'sociedades'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c073d7d-b45a-45d3-ae1c-c82b967d7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0391cbd8-7ad5-40a1-b4e4-ac75e3f52295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Los artistas han utilizado una variedad de técnicas y materiales para expresar su creatividad y transmitir mensajes emocionales, políticos y sociales a través de sus obras.\n",
      ". La historia del arte abarca una amplia gama de estilos, períodos y movimientos artísticos a lo largo de los siglos\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8aa9020-d5f3-4004-b07c-c7e6dcb8af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cuisine française est réputée dans le monde entier pour sa diversité, son raffinement et sa tradition culinaire\n",
      "Des plats emblématiques tels que le coq au vin, le boeuf bourguignon et les macarons ont conquis les palais des gourmets du monde entier\n",
      "Les chefs français sont célèbres pour leur créativité et leur utilisation experte des ingrédients locaux pour créer des plats délicieux et élégants qui incarnent l'art de la gastronomie.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"3.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dda683b-d775-4ccd-8bf9-1606fd00714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['La', 'cuisine', 'française', 'est', 'réputée', 'dans', 'le', 'monde', 'entier', 'pour', 'sa', 'diversité,', 'son', 'raffinement', 'et', 'sa', 'tradition', 'culinaire'], ['Des', 'plats', 'emblématiques', 'tels', 'que', 'le', 'coq', 'au', 'vin,', 'le', 'boeuf', 'bourguignon', 'et', 'les', 'macarons', 'ont', 'conquis', 'les', 'palais', 'des', 'gourmets', 'du', 'monde', 'entier'], ['Les', 'chefs', 'français', 'sont', 'célèbres', 'pour', 'leur', 'créativité', 'et', 'leur', 'utilisation', 'experte', 'des', 'ingrédients', 'locaux', 'pour', 'créer', 'des', 'plats', 'délicieux', 'et', 'élégants', 'qui', 'incarnent', \"l'art\", 'de', 'la', 'gastronomie.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd44bf2f-c6bd-42d4-a29e-e6f48a011782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19674689-9f7e-45b8-80c7-71558f1b8d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.20412415 0.186339  ]\n",
      " [0.20412415 0.         0.27386128]\n",
      " [0.186339   0.27386128 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb4b8e0b-0e2b-4b99-a158-8596cd62c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.2982432051815699, 1: 0.3569434467208233, 2: 0.3448133480976067}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2976d424-e770-4574-9af1-e8b75cd8f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.3569434467208233, ['Des', 'plats', 'emblématiques', 'tels', 'que', 'le', 'coq', 'au', 'vin,', 'le', 'boeuf', 'bourguignon', 'et', 'les', 'macarons', 'ont', 'conquis', 'les', 'palais', 'des', 'gourmets', 'du', 'monde', 'entier']), (0.3448133480976067, ['Les', 'chefs', 'français', 'sont', 'célèbres', 'pour', 'leur', 'créativité', 'et', 'leur', 'utilisation', 'experte', 'des', 'ingrédients', 'locaux', 'pour', 'créer', 'des', 'plats', 'délicieux', 'et', 'élégants', 'qui', 'incarnent', \"l'art\", 'de', 'la', 'gastronomie.\\n']), (0.2982432051815699, ['La', 'cuisine', 'française', 'est', 'réputée', 'dans', 'le', 'monde', 'entier', 'pour', 'sa', 'diversité,', 'son', 'raffinement', 'et', 'sa', 'tradition', 'culinaire'])]\n"
     ]
    }
   ],
   "source": [
    "#Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348d578f-56d3-4484-a3af-57c4d260f2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  3\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8153bdf4-86a8-4a40-b402-780a187ead5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Des plats emblématiques tels que le coq au vin, le boeuf bourguignon et les macarons ont conquis les palais des gourmets du monde entier. Les chefs français sont célèbres pour leur créativité et leur utilisation experte des ingrédients locaux pour créer des plats délicieux et élégants qui incarnent l'art de la gastronomie.\n",
      ". La cuisine française est réputée dans le monde entier pour sa diversité, son raffinement et sa tradition culinaire\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07a9a04e-56cb-49ca-b49c-0538d76cc4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Künstliche Intelligenz (KI) bezieht sich auf die Fähigkeit von Maschinen und Computern, Aufgaben auszuführen, die normalerweise menschliche Intelligenz erfordern\n",
      "Dazu gehören das Lernen, das Problemlösen, die Spracherkennung und die Entscheidungsfindung\n",
      "KI-Technologien wie maschinelles Lernen und neuronale Netze werden in verschiedenen Bereichen eingesetzt, von autonomen Fahrzeugen und Robotern bis hin zu personalisierten Empfehlungssystemen und medizinischer Diagnose.\n",
      "\n",
      "Sentences are  [['Künstliche', 'Intelligenz', '(KI)', 'bezieht', 'sich', 'auf', 'die', 'Fähigkeit', 'von', 'Maschinen', 'und', 'Computern,', 'Aufgaben', 'auszuführen,', 'die', 'normalerweise', 'menschliche', 'Intelligenz', 'erfordern'], ['Dazu', 'gehören', 'das', 'Lernen,', 'das', 'Problemlösen,', 'die', 'Spracherkennung', 'und', 'die', 'Entscheidungsfindung'], ['KI-Technologien', 'wie', 'maschinelles', 'Lernen', 'und', 'neuronale', 'Netze', 'werden', 'in', 'verschiedenen', 'Bereichen', 'eingesetzt,', 'von', 'autonomen', 'Fahrzeugen', 'und', 'Robotern', 'bis', 'hin', 'zu', 'personalisierten', 'Empfehlungssystemen', 'und', 'medizinischer', 'Diagnose.\\n']]\n"
     ]
    }
   ],
   "source": [
    "file = open(\"4.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7073b70c-0baf-4ea0-99f9-c300574516a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0c107e1-d456-496b-ad54-ead4dde7fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.26919095 0.14980118]\n",
      " [0.26919095 0.         0.13912167]\n",
      " [0.14980118 0.13912167 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a614db27-c878-4895-917c-8cfdbd90d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.3706637436963573, 1: 0.3618849304790072, 2: 0.2674513258246353}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a6f05bb-8417-469f-979c-1b67d0e28f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.3706637436963573, ['Künstliche', 'Intelligenz', '(KI)', 'bezieht', 'sich', 'auf', 'die', 'Fähigkeit', 'von', 'Maschinen', 'und', 'Computern,', 'Aufgaben', 'auszuführen,', 'die', 'normalerweise', 'menschliche', 'Intelligenz', 'erfordern']), (0.3618849304790072, ['Dazu', 'gehören', 'das', 'Lernen,', 'das', 'Problemlösen,', 'die', 'Spracherkennung', 'und', 'die', 'Entscheidungsfindung']), (0.2674513258246353, ['KI-Technologien', 'wie', 'maschinelles', 'Lernen', 'und', 'neuronale', 'Netze', 'werden', 'in', 'verschiedenen', 'Bereichen', 'eingesetzt,', 'von', 'autonomen', 'Fahrzeugen', 'und', 'Robotern', 'bis', 'hin', 'zu', 'personalisierten', 'Empfehlungssystemen', 'und', 'medizinischer', 'Diagnose.\\n'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72eafa37-e3d3-4d1b-a3b8-a9abedad2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary?  4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m summarize_text \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m----> 6\u001b[0m       summarize_text\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ranked_sentence[i][\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a3d57-5c1d-4be2-838d-26d5e0c68b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26949cd0-845f-4d01-abf3-8e85675ac2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"5.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f605630-29b7-449c-b2da-8bfad8f352f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb09c70-cc06-40be-af77-8dbf25c074e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9dd9c9-bff4-4c1d-a78b-3cc7eaa48798",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868a1c1-c0cb-4b28-b406-254ecd1d0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc1b07-8b63-4640-b00a-9f330baf94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ed44c-cca6-46f6-8ad2-bfb7e007b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46e1a8-ac0f-4a24-83db-3bd7eba04859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33413f55-3fc7-4b77-b88e-2a6d12c3047f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
